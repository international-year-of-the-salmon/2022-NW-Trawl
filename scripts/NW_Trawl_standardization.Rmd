---
title: "2022-NW-Trawl"
author: "Tim van der Stap"
date: "6/16/2022"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(lubridate)
library(readxl)
library(here)
library(lubridate)
library(obistools)
knitr::opts_chunk$set(echo = TRUE)
```

When downloading the file from the GitHub repo, make sure that you select the correct version.

```{r data download, include=FALSE}
download.file("https://github.com/international-year-of-the-salmon/2022-NW-Data-Template/blob/main/IYS2022_NW_Data.xlsx?raw=true", here::here("IYS_data_template", "IYS2022_NW_Data.xlsx"), quiet = TRUE, mode = "wb")

event <- read_excel(here::here("IYS_data_template", "IYS2022_NW_Data.xlsx"), sheet = "Sampling_Event_Info")
```

Create Event Core:

```{r event, include = FALSE}
event <- event %>% filter(Event_Type == "CanTrawl") %>%
  mutate(Time_Start = as.POSIXct(Time_Start, format = "%H:%M:%S"),
         Time_End = as.POSIXct(Time_End, format = "%H:%M:%S")) %>%
  mutate(Time_Start = strftime(Time_Start, format = "%H:%M:%S"),
         Time_End = strftime(Time_End, format = "%H:%M:%S")) %>%
  mutate(eventDate_start = paste0(format_ISO8601(as.POSIXct(paste0(as_date(
    paste0(Year, "-", Month, "-", Day)), " ", Time_Start), tz ="UTC")), "Z"),
         eventDate_finish = paste0(format_ISO8601(as.POSIXct(paste0(as_date(
    paste0(Year, "-", Month, "-", Day)), " ", Time_End), tz = "UTC")), "Z"))

# Quick manual QAQC to ensure that there's no sampling event occurring over 2 days:
time_QAQC <- event %>% select(Station, Year, Month, Day, Time_Start, Time_End, eventDate_start, eventDate_finish)

# For Station 1, sampling occurred across midnight, and so the time_start and time_end are on different days. Change dates accordingly:
station1 <- event %>% filter(Station == 1) %>%
  mutate(eventDate_finish = as.Date(eventDate_finish) + 1) %>%
  mutate(eventDate_finish = paste0(eventDate_finish, "T", Time_End, "Z"))

nw_event <- subset(event, Station != 1)
event <- rbind(nw_event, station1) %>% arrange(Station)

# Create final eventDate and QC
event <- event %>%
  mutate(eventDate = paste(eventDate_start, eventDate_finish, sep = "/"))
obistools::check_eventdate(event)
```

Create function to determine polygon coordinates required for the metadata:

```{r polygon coordinates, include = FALSE}
polygon_coords <- function(event){
  event <- event %>% select(Latitude_Start_DecDeg, Longitude_Start_DecDeg) %>% 
    drop_na(Latitude_Start_DecDeg, Longitude_Start_DecDeg) 
  ch <- chull(event)
  coords <- event[c(ch, ch[1]), ]
  coords <- paste(coords$Latitude_Start_DecDeg, coords$Longitude_Start_DecDeg, sep = ",", collapse = " ")
  coords
}
```

Create Event Core:

```{r event_core, include = FALSE}
event$Year <- as.numeric(format(as.Date(event$eventDate), "%Y"))
event$Month <- as.numeric(format(as.Date(event$eventDate), "%m"))
event$Day <- as.numeric(format(as.Date(event$eventDate), "%d"))

event_coordinates <- event %>%
  select(eventID = Station_Event_ID,
         Longitude_Start_DecDeg, Latitude_Start_DecDeg,
         Longitude_End_DecDeg, Latitude_End_DecDeg) %>%
  distinct(eventID, .keep_all = TRUE) %>%
    mutate(footprintWKT = paste("LINESTRING (", Longitude_Start_DecDeg, Latitude_Start_DecDeg, ",", 
                              Longitude_End_DecDeg, Latitude_End_DecDeg, ")")) 

event_linestring <- obistools::calculate_centroid(event_coordinates$footprintWKT)
event_linestring <- cbind(event_coordinates, event_linestring) %>%
  select(eventID, footprintWKT, decimalLatitude, decimalLongitude, coordinateUncertaintyInMeters)

event_trawl <- event %>%
  select(eventID = Station_Event_ID,
         eventDate,
         Year, Month, Day,
         minimumDepthInMeters = Minimum_Sampling_Depth,
         maximumDepthInMeters = Maximum_Sampling_Depth) %>%
  left_join(event_linestring, by = "eventID") %>%
  distinct(eventID, .keep_all = TRUE) %>%
  mutate(geodeticDatum = "WGS84")

# Save locally:
write_csv(event_trawl, here("standardized_data", "NW2022_event.csv"))
```

Next, create the occurrence extension for the overall catch: 

```{r occurrence overall catch, eval = FALSE}
occurrence_allCatch <- read_excel("C:/Users/Admin/Desktop/GitHub/2022-NW-Trawl/IYS_data_template/IYS2022_NW_Data.xlsx", sheet = "Catch_Info")

occurrence_allCatch <- occurrence_allCatch %>%
  mutate(identificationQualifier = ifelse(grepl("sp.", occurrence_allCatch$Scientific_Name), "sp. indet", ""))
occurrence_allCatch$Scientific_Name <- gsub("\\b sp.", "", occurrence_allCatch$Scientific_Name)
occurrence_allCatch <- occurrence_allCatch %>% rename(scientificname = Scientific_Name)
unique_spp <- unique(occurrence_allCatch$scientificname) %>% as.data.frame()
colnames(unique_spp) <- "scientificname"

# Assign WoRMS LSID to the unique species:
worms_id <- worrms::wm_records_names(unique(occurrence_allCatch$scientificname), marine_only = FALSE) %>% dplyr::bind_rows()

# Find out which species are not found in the WoRMS database:
worms_occ <- left_join(unique_spp, worms_id, by = "scientificname") %>% 
  filter(is.na(AphiaID)) %>% distinct(scientificname)

# Change the taxa names accordingly: 
occurrence_allCatch$scientificname <- str_replace(occurrence_allCatch$scientificname, " \\s*\\([^\\)]+\\)", "") # removes class
occurrence_allCatch$scientificname <- gsub("Phacellophora camtchatica", 
                                           "Phacellophora camtschatica", occurrence_allCatch$scientificname)
occurrence_allCatch$scientificname <- gsub("Glyptocephalus zachiris",
                                           "Glyptocephalus zachirus", occurrence_allCatch$scientificname)
occurrence_allCatch$scientificname <- gsub("Argropelecus sladeni",
                                           "Argyropelecus sladeni", occurrence_allCatch$scientificname)

# So now we can run worrms::wm_records_names again, and there should be no NA in the AphiaID column. Be sure to inspect the result as sometimes multiple AphiaIDs are generated for the same taxa.    
occurrence_allCatch_id <- worrms::wm_records_names(unique(occurrence_allCatch$scientificname), marine_only = FALSE) %>% bind_rows() 

# Omit certain AphiaIDs that do not apply:
occurrence_allCatch_id <- occurrence_allCatch_id %>% filter(!AphiaID %in% "1077913")

# Now that all unique entries have a WoRMS ID, connect this to the original data frame:
nw_occurrence_all <- left_join(occurrence_allCatch_id, occurrence_allCatch, by = "scientificname")

# Omit biomass data from the occurrence extension:
nw_occurrence <- nw_occurrence_all %>%
  mutate(specificEpithet = stringr::word(scientificname, 2)) %>%
  select(eventID = `Station Event ID`, occurrenceID = `Catch ID`, 
         scientificName = scientificname,
         scientificNameID = `lsid`, 
         scientificNameAuthorship = authority,
         taxonomicStatus = status,
         taxonRank = rank, 
         lifeStage = Lifestage,
         vernacularName = Species_Recorded, 
         individualCount = Catch_Count, identificationQualifier, kingdom, phylum, class, order, family, genus, specificEpithet) %>% distinct() %>%
  mutate(basisOfRecord = "HumanObservation",
         occurrenceStatus = "present")

# Save locally:
write_csv(nw_occurrence_all, here("standardized_data", "occurrence_trawl_all.csv"))
```

Next, create the occurrence extension for the specimen catch: 

```{r occurrence overall catch, eval = FALSE}
occurrence_specimen <- read_excel("C:/Users/Admin/Desktop/GitHub/2022-NW-Trawl/IYS_data_template/IYS2022_NW_Data_v1.xlsx", sheet = "Specimen_Info")

occurrence_specimen <- occurrence_specimen %>%
  mutate(identificationQualifier = ifelse(grepl("sp.", occurrence_specimen$Scientific_Name), "sp. indet", ""))
occurrence_specimen$Scientific_Name <- gsub("\\b sp.", "", occurrence_specimen$Scientific_Name)

occurrence_specimen <- occurrence_specimen %>% rename(scientificname = Scientific_Name)
unique_spp_specimen <- unique(occurrence_specimen$scientificname) %>% as.data.frame()
colnames(unique_spp_specimen) <- "scientificname"

# Assign WoRMS LSID to the unique species:
worms_id <- worrms::wm_records_names(unique(occurrence_specimen$scientificname), marine_only = FALSE) %>% dplyr::bind_rows()

# Find out which species are not found in the WoRMS database:
worms_occ <- left_join(unique_spp_specimen, worms_id, by = "scientificname") %>% 
  filter(is.na(AphiaID)) %>% distinct(scientificname)

# Change the taxa names accordingly: 
occurrence_specimen$scientificname <- gsub("Phacellophora camtchatica", 
                                           "Phacellophora camtschatica", occurrence_specimen$scientificname)
occurrence_specimen$scientificname <- gsub("Argropelecus sladeni",
                                           "Argyropelecus sladeni", occurrence_specimen$scientificname)

# So now we can run worrms::wm_records_names again, and there should be no NA in the AphiaID column. Be sure to inspect the result as sometimes multiple AphiaIDs are generated for the same taxa.    
occurrence_specimen_id <- worrms::wm_records_names(unique(occurrence_specimen$scientificname), marine_only = FALSE) %>% bind_rows() 

# Omit certain AphiaIDs that do not apply:
occurrence_specimen_id <- occurrence_specimen_id %>% filter(!AphiaID %in% "1077913")

# Now that all unique entries have a WoRMS ID, connect this to the original data frame:
nw_occurrence_specimen <- left_join(occurrence_specimen_id, occurrence_specimen, by = "scientificname")

# Omit biomass data from the occurrence extension:
nw_occ_specimen <- nw_occurrence_specimen %>%
  mutate(specificEpithet = stringr::word(scientificname, 2)) %>%
  select(eventID = `Station Event ID`, occurrenceID = `Specimen ID`, 
         scientificName = scientificname,
         scientificNameID = `lsid`, 
         scientificNameAuthorship = authority,
         taxonomicStatus = status,
         taxonRank = rank, 
         lifeStage = Lifestage,
         vernacularName = Species_Recorded, 
         identificationQualifier, kingdom, phylum, class, order, family, genus, specificEpithet) %>% distinct() %>%
  mutate(basisOfRecord = "HumanObservation",
         occurrenceStatus = "present")

# Save locally:
write_csv(nw_occ_specimen, here("standardized_data", "occurrence_trawl_specimen.csv"))
```

Combine both occurrence extensions into a final data table:

```{r occurrence, eval = FALSE}
NW2022_occ <- dplyr::bind_rows(nw_occurrence, nw_occ_specimen)

# To re-order the occurrenceID, use following code:
order <- stringr::str_sort(NW2022_occ$occurrenceID, numeric=TRUE)
NW2022_occ <- NW2022_occ[match(order, NW2022_occ$occurrenceID),]

# Remove NA and replace with empty cells:
NW2022_occ <- sapply(NW2022_occ, as.character)
NW2022_occ[is.na(NW2022_occ)] <- ""
NW2022_occ <- as.data.frame(NW2022_occ)

# Check if occurrenceIDs are all unique - answer should be TRUE:
length(unique(NW2022_occ$occurrenceID)) == nrow(NW2022_occ)
# Save the occurrence Core locally and in Google Drive:
write_csv(NW2022_occ, here("standardized_data", "NW2022_occ.csv"))
```

Create resourceRelationship extension: 

```{r resourceRelationship, eval = FALSE}
NW2022_resourceRelationship <- NW2022_occ %>%
  select(eventID, occurrenceID, scientificName, individualCount)
NW2022_resourceRelationship$individualCount <- as.numeric(NW2022_resourceRelationship$individualCount)
  
NW2022_resourceRelationship <- NW2022_resourceRelationship %>%
  mutate(resourceID = ifelse(is.na(individualCount), NW2022_occ$occurrenceID, NA)) %>%
  group_by(eventID, scientificName) %>%
  filter(n() != 1) %>%
  ungroup()

NW2022_resourceRelationship <- NW2022_resourceRelationship %>%
  mutate(relatedResourceID = ifelse(is.na(individualCount), NA, NW2022_occ$occurrenceID)) %>%
  mutate(relationshipOfResource = ifelse(!is.na(resourceID), "is a subset of", NA)) %>%
  dplyr::arrange(eventID, scientificName) %>%
  fill(relatedResourceID) %>%
  filter(!is.na(resourceID))

order <- stringr::str_sort(NW2022_resourceRelationship$resourceID, numeric = TRUE)
NW2022_resourceRelationship <- NW2022_resourceRelationship[match(order, NW2022_resourceRelationship$resourceID),]
NW2022_resourceRelationship <- NW2022_resourceRelationship %>%
  mutate(resourceRelationshipID = paste(relatedResourceID, "rr", sep = "-"),
         ID = sprintf("%03d", row_number()),
         resourceRelationshipID = paste(resourceRelationshipID, ID, sep = "-")) %>%
  select(eventID, resourceRelationshipID, resourceID, relationshipOfResource, relatedResourceID)

write_csv(NW2022_resourceRelationship, here("standardized_data", "NW2022_resourceRelationship.csv"))
```

Create eMOF extension data table:

```{r eMOF, eval = FALSE}
NW2022_trawl_allCatch_eMOF <- nw_occurrence_all %>%
  select(eventID = `Station Event ID`,
         occurrenceID = `Catch ID`,
         individualCount = Catch_Count,
         Catch_Weight,
         Lifestage) %>%
  mutate_all(as.character) %>%
  pivot_longer(cols = c(individualCount:Lifestage),
               names_to = "measurementType",
               values_to = "measurementValue") %>%
  mutate(measurementMethod = ifelse(measurementType == "individualCount", "Total", NA))

NW2022_trawl_allCatch_eMOF <- NW2022_trawl_allCatch_eMOF %>%
  mutate(measurementID = paste0(occurrenceID, measurementType, sep = ":"),
         measurementTypeID = case_when(
           measurementType == "individualCount" ~ "http://vocab.nerc.ac.uk/collection/P01/current/OCOUNT01/",
           measurementType == "Catch_Weight" ~ "http://vocab.nerc.ac.uk/collection/S06/current/S0600088/",
           measurementType == "Lifestage" ~ "http://vocab.nerc.ac.uk/collection/P01/current/LSTAGE01/"),
         measurementUnit = case_when(
           measurementType == "individualCount" ~ "individuals",
           measurementType == "Catch_Weight" ~ "kilogram"),
         measurementUnitID = case_when(
           measurementUnit == "kilogram" ~ "http://vocab.nerc.ac.uk/collection/P06/current/KGXX/",
           measurementUnit == "individuals" ~ "http://vocab.nerc.ac.uk/collection/P06/current/UUUU/"),
         measurementValueID = case_when(
           measurementValue == "None" ~ "http://vocab.nerc.ac.uk/collection/S11/current/S1131/",
           measurementValue == "Immature" ~ "http://vocab.nerc.ac.uk/collection/S11/current/S1171/",
           measurementValue == "Larval" ~ "http://vocab.nerc.ac.uk/collection/S11/current/S1128/",
           measurementValue == "Age 1+" ~ "http://vocab.nerc.ac.uk/collection/S11/current/S1116/")) %>%
  select(eventID, occurrenceID, measurementID, measurementType, measurementTypeID, measurementValue, measurementValueID,
         measurementUnit, measurementUnitID, measurementMethod)

# And for the individual specimen data:
NW2022_ind_eMOF <- nw_occurrence_specimen %>%
  select(eventID = `Station Event ID`,
         occurrenceID = `Specimen ID`, 
         Lifestage, Length, Weight, Sex) %>%
  mutate_all(as.character) %>%
  pivot_longer(cols = Lifestage:Sex,
               names_to = "measurementType", 
               values_to = "measurementValue") %>%
  mutate(measurementID = paste(occurrenceID, measurementType, sep = "-"),
         measurementTypeID = case_when(
           measurementType == "Lifestage" ~ "http://vocab.nerc.ac.uk/collection/P01/current/LSTAGE01/",
           measurementType == "Sex" ~ "http://vocab.nerc.ac.uk/collection/P01/current/ENTSEX01/",
           measurementType == "Length" ~ "http://vocab.nerc.ac.uk/collection/P01/current/OBSINDLX/",
           measurementType == "Weight" ~ "http://vocab.nerc.ac.uk/collection/S06/current/S0600088/"),
         measurementUnit = case_when(
           measurementType == "Length" ~ "centimeters",
           measurementType == "Weight" ~ "kilograms"),
         measurementUnitID = case_when(
           measurementUnit == "kilograms" ~ "http://vocab.nerc.ac.uk/collection/P06/current/KGXX/",
           measurementUnit == "centimeters" ~ "http://vocab.nerc.ac.uk/collection/P06/current/ULCM/"),
         measurementValueID = case_when(
           measurementValue == "Unsexed" ~ "https://vocab.nerc.ac.uk/collection/S10/current/S104/",
           measurementValue == "Female" ~ "http://vocab.nerc.ac.uk/collection/S10/current/S102/",
           measurementValue == "Male" ~ "https://vocab.nerc.ac.uk/collection/S10/current/S103/",
           measurementValue == "None" ~ "http://vocab.nerc.ac.uk/collection/S11/current/S1131/",
           measurementValue == "Immature" ~ "http://vocab.nerc.ac.uk/collection/S11/current/S1171/",
           measurementValue == "Age 1+" ~ "http://vocab.nerc.ac.uk/collection/S11/current/S1116/")) %>%
  select(eventID, occurrenceID, measurementID, measurementType, measurementTypeID, measurementValue, measurementValueID,
         measurementUnit, measurementUnitID)
```

Combine the two extended measurementOrFact extensions into a single eMOF extension, and save locally and in GoogleDrive:

``` {r}
NW2022_eMOF <- dplyr::bind_rows(NW2022_trawl_allCatch_eMOF, NW2022_ind_eMOF)

# Remove NA and replace with empty cells:
NW2022_eMOF <- sapply(NW2022_eMOF, as.character)
NW2022_eMOF[is.na(NW2022_eMOF)] <- ""
NW2022_eMOF <- as.data.frame(NW2022_eMOF)

write_csv(NW2022_eMOF, here("standardized_data", "NW2022_eMOF.csv"))
```

